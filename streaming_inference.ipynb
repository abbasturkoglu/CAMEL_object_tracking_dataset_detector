{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "from detector.detector import get_transform, get_fasterrcnn_model\n",
    "\n",
    "\n",
    "bootstrap_servers = ['kafka1:9091']\n",
    "topicName = 'my-test-video'\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers = bootstrap_servers)\n",
    "\n",
    "path = './data/sequence-1/img1'\n",
    "image_filenames = sorted(os.listdir(path))[:4]\n",
    "\n",
    "\n",
    "\n",
    "for image_name in :\n",
    "    producer.send(topicName, )\n",
    "    producer.flush()\n",
    "\n",
    "\n",
    "consumer = KafkaConsumer('my-test-video', bootstrap_servers=['kafka1:9091'])\n",
    "\n",
    "for message in consumer:\n",
    "    print (message)\n",
    "                          \n",
    "\n",
    "def make_detections_on_image_stream(path, model):\n",
    "\n",
    "    image_id = -1\n",
    "\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "\n",
    "    transform = get_transform(False)\n",
    "    model = model.eval()\n",
    "\n",
    "    all_frame_results_array = None\n",
    "\n",
    "    # checks whether frames were extracted\n",
    "    success = 1\n",
    "\n",
    "    while success:\n",
    "\n",
    "        success, image = vidObj.read()\n",
    "\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        # img = Image.open('./data/sequence-1/img1/000608.jpg').convert(\"RGB\")\n",
    "\n",
    "        image_tensor = transform(image, {})\n",
    "        image_tensor = image_tensor[0].unsqueeze(0).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(image_tensor)\n",
    "\n",
    "        for frame in zip(predictions):\n",
    "\n",
    "            frame = frame[0]\n",
    "            image_id += 1\n",
    "            boxes = frame['boxes'].cpu().numpy()\n",
    "            labels = frame['labels'].cpu().numpy().reshape(-1,1)\n",
    "            scores = frame['scores'].cpu().numpy().reshape(-1,1)\n",
    "            image_id_col = np.array([image_id]*scores.shape[0]).reshape(-1,1)\n",
    "            x = np.array([-1]*scores.shape[0]).reshape(-1,1)\n",
    "            y = np.array([-1]*scores.shape[0]).reshape(-1,1)\n",
    "            z = np.array([-1]*scores.shape[0]).reshape(-1,1)\n",
    "\n",
    "            # Convert bbox coords to tlwh from tlbr\n",
    "            boxes[:,2] = boxes[:,2]-boxes[:,0]\n",
    "            boxes[:,3] = boxes[:,3]-boxes[:,1]\n",
    "\n",
    "            frame_results = np.hstack([image_id_col, labels, boxes, scores, x, y, z])\n",
    "\n",
    "            if all_frame_results_array is not None:\n",
    "                all_frame_results_array = np.vstack([all_frame_results_array, frame_results])\n",
    "            else:\n",
    "                all_frame_results_array = frame_results\n",
    "\n",
    "        np.savetxt(os.path.join('det.txt'), all_frame_results_array, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
